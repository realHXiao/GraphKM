# GraphKM
![image](https://github.com/realHXiao/GraphKM/assets/71002556/1261ebdd-7248-458f-a1af-e6089c9cee34)

## Introduction
The GraphKM toolbox is a Python package for prediction of KMs. 
## Requirements
Assuming that you use [Miniconda](https://docs.conda.io/en/latest/miniconda.html) or [Anaconda](https://www.anaconda.com/). In a terminal execute: 
```
conda env create -n GraphKM python=3.8
conda activate GraphKM
```
 Requirement packages: 
```
paddlehelix==1.0.1
pgl==2.2.4
paddlepaddle-gpu==2.3.2
matplotlib
scikit-learn
rdkit
PubChemPy
xgboost==1.7.5
hyperopt==0.2.7
ESM-2
```
Note: ``paddlepaddle-gpu==2.3.2`` is installed by command line ``conda install paddlepaddle-gpu==2.3.2 cudatoolkit=11.2 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/ -c conda-forge``. 

Please reference [this github site](https://github.com/facebookresearch/esm) for ESM-2 installation. 

## Input files
Before data preprocessing, a json file and a csv file should be ready. 

+ The json file is generated by codes in the `KM_data_clean/` dictionary, and is composed by dictionaries, like:
    ```
    [
        {
            "ECNumber": "2.1.1.22",
            "Organism": "Rattus norvegicus",
            "Smiles": "C[S+](CCC(C(=O)[O-])N)CC1C(C(C(O1)N2C=NC3=C(N=CN=C32)N)O)O",
            "Substrate": "S-Adenosyl-L-methionine",
            "Sequence": "MQRRRRAPPASQPAQDSGHSEEVEVQFSAGRLGSAAPAGPPVRGTAEDEERLEREHFWKVINAFRYYGTSMHERVNRTERQFRSLPDNQQKLLPQFPLHLDKIRKCVDHNQEILLTIVNDCIHMFENKEYGEDANGKIMPASTFDMDKLKSTLKQFVRDWSGTGKAERDACYKPIIKEIIKNFPKERWDPSKVNILVPGAGLGRLAWEIAMLGYACQGNEWSFFMLFSSNFVLNRCSEVDKYKLYPWIHQFSNNRRSADQIRPIFFPDVDPHSLPPGSNFSMTAGDFQEIYSECNTWDCIATCFFIDTAHNVIDYIDTIWRILKPGGIWINLGPLLYHFENLANELSIELSYEDIKNVVLQYGFQLEVEKESVLSTYTVNDLSMMKYYYECVLFVVRKPQ",
            "Type": "wildtype",
            "Value": "0.042",
            "Unit": "mM"
        }
    ]
    ```

## Train
### Preprocess
```
python data_preprocess.py -i my_data.json -l KM -input_seq my_protein_sequences_embeddings.csv -o my_dataset.npz
```
### Training
The training needs big memory if you use GPU for acceleration. Suggestion that the memory of your GPU is 24 GB. 

```
python train.py -d path_to/my_dataset.npz --model_config path_to/gin_config.json -l KM -- model_dir path_to/ --results_dir path_to/

python train_xgb.py -i path_to/my_data.json -l KM -input_seq path_to/my_protein_sequences_embeddings.csv -m path_to/best_model_gin_-1_lr0.0005.pdparams --model_config path_to/gin_config.json
```
## Evaluation results on the cleaned dataset:
| Methods      |  MSE       | r.m.s.e.  | R2        |
| :--:         | :--:       | :--:      | :--:      |
| GIN          | 0.639      | 0.799     | 0.614     |
| GAT          | 0.709      | 0.842     | 0.572     |
| GCN          | 0.671      | 0.819     | 0.595     |
| GAT_GCN      | 0.627      | 0.792     | 0.622     |

## Prediction
The input for prediction.py:
+ If you want to predict KM values of different seuqences corresponding to different substrate SMILES codes, use csv file as input. The format of csv file please refer to the example.csv file. The commond line example for prediction:

    ```
    python prediction.py -c --csv_file example.csv -l KM -input_seq example.tsv -m path_to/best_model_gin_-1_lr0.0005.pdparams --model_config gin_config.json -xgb path_to/gin_xgboost_model.dat
    ```
+ If you want to predict KM values of different seuqences corresponding to one type substrate SMILES codes, use FASTA file as input. 

    commond line example for prediction:
    ```
    python prediction.py -l KM -f --fasta_file example.fasta -input_seq my_sequences_embeddings.tsv -S substrate.txt -m path_to/best_model_gin_-1_lr0.0005.pdparams --model_config path_to/gin_config.json -xgb path_to/gin_xgboost_model.dat
    ```
## tip
Enter `-h` tag for more helps. 
```
python data_preprocess.py -h
python train.py -h
python train_xgb.py -h
python prediction.py -h
```
